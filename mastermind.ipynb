{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72242fd7-0750-40ee-8ed4-755c1df52b1c",
   "metadata": {},
   "source": [
    "# Can I build a neural network to solve Mastermind, and how will it compare with Knuth's algorithm?\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://m.media-amazon.com/images/I/612QbEzSafL._AC_SL1500_.jpg\"\n",
    "         alt=\"Box top from Mastermind game.\"\n",
    "         width=\"400px\"\n",
    "        />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a4bd3-812e-4a2d-af1e-f4791cd1a06c",
   "metadata": {},
   "source": [
    "## 2025-05-19: Intro\n",
    "\n",
    "I started using Gemini about a month ago, so although I've never tried to build a neural network, recently I've been thinking more about them. While staring at the <a href=\"https://en.wikipedia.org/wiki/Mastermind_(board_game)\">Mastermind</a> board my kids left out, I started thinking about whether I could build a neural network to solve it. This would be overpowered, of course. While researching the game, I quickly stumbled across Donald Knuth's algorithm, which I immediately stopped reading about so I could think it through and implement it myself.\n",
    "\n",
    "The plan here, I think, is:\n",
    "1. Build a game environment.\n",
    "2. Implement Knuth's algorithm.\n",
    "3. Build a neural network.\n",
    "\n",
    "The game environment should be able to return the latest result or all results; I gather I shouldn't ask my neural network to manage the game's history. I may try to build the neural network myself using NumPy. I just discovered <a href=\"https://www.youtube.com/playlist?list=PLQVvvaa0QuDcjD5BAw2DxE6OF2tius3V3\">this playlist</a>, and I've been meaning to revisit the first few videos of <a href=\"https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\">3blue1brown's</a> for the ?th time.\n",
    "\n",
    "Initial thoughts for the game environment:\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "class Mastermind:\n",
    "    def __init__(self, return_history=False, seed=None):\n",
    "        self.secret = None\n",
    "        self.return_history = return_history\n",
    "        self.history = []\n",
    "        self.reset(seed)\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        self.secret = random.choices(range(1, 7), k=4)\n",
    "        self.history.clear()\n",
    "\n",
    "    def step(self, guess):\n",
    "        # score guess; determine how many black and white pegs\n",
    "        # append (guess, score) to history\n",
    "        return self.history[:] if self.return_history else self.history[-1]\n",
    "```\n",
    "\n",
    "Now that I think about it, I'm not sure what data structure I'll need to feed into the neural network. But I can work that out when I get there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ef07c-3f64-40e6-95ed-44b8c52278b0",
   "metadata": {},
   "source": [
    "## 2025-05-20: Game Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a6826f-7b4f-479f-8ce4-b00a4bf0fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842c9d9e-0eff-493f-a207-10d0c61ea53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mastermind:\n",
    "    def __init__(self, return_history=False, seed=None):\n",
    "        self.secret = None\n",
    "        self.secret_counts = Counter()\n",
    "        self.return_history = return_history\n",
    "        self.history = []\n",
    "        self.reset(seed)\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self.secret_counts.clear()\n",
    "        self.history.clear()\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        self.secret = random.choices(range(1, 7), k=4)\n",
    "        self.secret_counts.update(self.secret)\n",
    "\n",
    "    def step(self, guess):\n",
    "        black = sum(self.secret[i] == guess[i] for i in range(4))\n",
    "        white = sum((self.secret_counts & Counter(guess)).values()) - black\n",
    "        score = (black, white)\n",
    "        self.history.append((guess, score))\n",
    "        return self.history[:] if self.return_history else score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a55618-8926-4ff1-bf1c-82050dce7956",
   "metadata": {},
   "source": [
    "One thing this class doesn't address so far is how to help carry out Knuth's algorithm. For each remaining possible guess $A$, I think I'll need to take each other remaining possible guess $B$ and say, if $B$ were the secret, what score would $A$ receive? And then group the $B$s by that score, and aggregate them to measure $A$'s suitability as the next guess.\n",
    "\n",
    "I'm starting to think that I don't need an actual game environment to carry out Knuth's algorithm.\n",
    "\n",
    "In any case, here's a test run that I solved manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12542adc-7a0f-4d90-8b75-3af65849ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Mastermind(seed='first test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee50f75e-695e-49e0-a1a3-50b78dfb0e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c770801-1a22-4fa1-b3ff-f13df37c8a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((2, 4, 5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af82ddad-ba7b-4713-bc5c-915144b81e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((4, 5, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84fdb87-b7d9-4148-aa03-7e2dbad910bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((6, 6, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040c9d3a-1b6f-4727-81a2-2970413f0091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((6, 1, 2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "007487f7-ea50-49c0-ae69-e6f00c6a4ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.step((5, 3, 6, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b06500c5-5bfa-4ff2-a472-ac3beac0792e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e43b5-9802-4444-9623-ce5306bfc571",
   "metadata": {},
   "source": [
    "During my neural network studying, I wondered how many output neurons I should have for Mastermind. I think I should use one-hot encoding, with each possible color of each peg having its own neuron, so I'll have $4 \\times 6 = 24$ output neurons.\n",
    "\n",
    "I'm starting to see a lot of possible issues with the input neurons, though. I could represent each previous guess and score with $4 \\times 6 + 2 \\times 5 = 34$ neurons, and there are a maximum of 9 previous guesses so that's $9 \\times 34 = 306$ input neurons. Maybe that's a lot? But here are some definite concerns:\n",
    "1. Much of the history will be empty/missing. I gather these inputs could be set to zero. Maybe the first layer biases as well?\n",
    "2. The order of previous guesses doesn't matter. I feel that brute-forcing through this would make training exponentially more difficult/expensive. I asked Gemini for some topics to look into: permutation invariance, set processing, aggregation functions and pooling, embedding functions, and deep sets. Among others. I may have picked a project that doesn't lend itself to a simple neural network.\n",
    "3. The different colors are interchangeable. This one, it seems, a neural network may actually be well suited to learn.\n",
    "\n",
    "Also, yes, I know, the `step` method above returns multiple types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb2e0a2-0939-409e-a333-5dffd054fe14",
   "metadata": {},
   "source": [
    "## 2025-06-03: Knuth's algorithm, first attempt\n",
    "\n",
    "### Trust\n",
    "\n",
    "It took me until yesterday to really understand what Knuth's algorithm does and does not try to do. I think I had subconsciously been stuck on the following possibility:\n",
    "\n",
    "Consider a game with 21 possibilities, two of which are $A$ and $B$. What if the possible results of $A$ split the remainder into groups of 16, 1, 1, 1, 1; and the possible results of $B$ split the remainder into groups of 4, 4, 4, 4, 4. The algorithm tells us to choose $B$. Now, what if these 21 possibilities were actually a subgame?\n",
    "\n",
    "What if, in the previous step, $X$ led to remainders of our 21 as well as 10, 9, 8; while $Y$ led to remainders of 12, 12, 12, 12? The algorithm tells us to choose $Y$ and forget about $X$. Even if each one of the possibilities $Z$ after $Y$ turns out to be 8, 1, 1, 1; even though the 4 from $(X \\rightarrow B)$ would be preferable to the 8 from $(Y \\rightarrow Z)$, we've committed to $Y$.\n",
    "\n",
    "Knuth's algorithm doesn't concern itself with this. It implicitly trusts that Mastermind is balanced in some way.\n",
    "\n",
    "### Grouping (incorrectly, it turns out)\n",
    "\n",
    "At each step Knuth's algorithm looks only one step ahead and picks a best arrangement. Without loss of generality, there are only five distinct partitions of the number 4, so we only need consider five first guesses. For subsequent guesses we'll achieve the same type of simplification by processing possibilities in sort order and only replacing the best one seen if we find one better.\n",
    "\n",
    "I missed something at first, though. For comparison, when I play Wordle, if I'm trying to avoid losing, I typically use 15 different letters in my first three guesses, even if I've gotten some hits in earlier guesses. Knuth's algorithm sometimes takes this approach, but when reading about Knuth's algorithm, as soon as I started to get the shape of it, I stopped reading. I wanted to work out the implementation details for myself, but it hadn't sunk in that I needed to consider all possible subsequent guesses, even if they were no longer possible solutions.\n",
    "\n",
    "I realized this after I had implemented an algorithm, run it, fixed a couple issues, and computed what seemed to be a full solution within just a few seconds. Then I played some sample games, and every so often my algorithm solved it in six guesses. After digging through the code a bit, without sharing my code I asked Gemini what the problem might be, and it suggested I may have missed this part of the algorithm, that I may need to consider guesses that have been ruled out as a potential solution.\n",
    "\n",
    "I then corrected for this, but when I ran what I thought was now Knuth's real algorithm, it ran for a day without finishing. I had also struggled along the way to work out how I should store the tree I was computing, which made my code rather ugly. So I'm scrapping pretty much everything until I have a more efficient way to compute everything. Here's what I may want to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4704bd2-272a-4a30-86c2-3bf1604995fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637e0ffe-c041-4099-9727-85d51a2d1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_possibilities = list(product(range(1, 7), repeat=4))\n",
    "\n",
    "starting_guesses = [\n",
    "    (1, 1, 1, 1),\n",
    "    (1, 1, 1, 2),\n",
    "    (1, 1, 2, 2),\n",
    "    (1, 1, 2, 3),\n",
    "    (1, 2, 3, 4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b601ac-83c6-4130-9ce4-4c1db3398ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(guess, possible):\n",
    "    black = sum(guess[i] == possible[i] for i in range(4))\n",
    "    white = sum((Counter(guess) & Counter(possible)).values()) - black\n",
    "    return (black, white)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885d1bb-f181-498f-bb87-422a93022f14",
   "metadata": {},
   "source": [
    "## 2025-06-04: Ideas on efficiency\n",
    "\n",
    "If I understand correctly, Knuth's algorithm requires doing the following many times: Given some subset of remaining possible solutions and a guess, I need to count how often across those possible solutions that guess would be given each possible score, and determine the maximum count.\n",
    "\n",
    "I think the most productive thing I could do is to be able to return a score extremely efficiently. Originally I thought I would cache the score function, which is useful, but the way I wrote the function feels like there would be a lot of Python overhead in retrieving from the cache. Two tuples where the individual values are numbers between 1 and 6 — should I go with bit packing?\n",
    "\n",
    "Eventually I realized that once we've enumerated the states and know how they compare with each other, it doesn't really matter how we identify them, as long as we can translate back for display. There are only $1{,}296 \\times 1{,}296 = 1{,}679{,}616$ different inputs to the function. These scores can be computed, stored in an array or list, and accessed by index. As I need to pull many of these values at once, I should use NumPy for its advanced indexing.\n",
    "\n",
    "The scores in this array can be bitpacked. Again, it doesn't matter what the values in the scores array are, as long as we can identify the win condition and translate back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "963a8f1a-d44d-49b9-818e-7cc6de262a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_guess(guess):\n",
    "    index = 0\n",
    "    for element in guess:\n",
    "        index *= 6\n",
    "        index += element - 1\n",
    "    return index\n",
    "\n",
    "def decode_guess(index):\n",
    "    guess = []\n",
    "    while len(guess) < 4:\n",
    "        index, r = divmod(index, 6)\n",
    "        guess.insert(0, r + 1)\n",
    "    return tuple(guess)\n",
    "\n",
    "assert all(guess == decode_guess(encode_guess(guess)) for guess in starting_possibilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe495f94-fabf-4def-9e6d-3064c2621e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_score(score):\n",
    "    black, white = score\n",
    "    return 16 * black + white\n",
    "\n",
    "def decode_score(score):\n",
    "    return divmod(score, 16)\n",
    "\n",
    "assert all((black, white) == decode_score(encode_score((black, white)))\n",
    "           for black in range(5) for white in range(5))\n",
    "\n",
    "WIN = encode_score((4, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c619918b-3775-4c5a-bf52-2041405a8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "602bfcb4-9bf2-428a-9d2d-bcf45b5ccaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.11 s, sys: 23 ms, total: 9.13 s\n",
      "Wall time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = np.empty((6**4, 6**4), dtype=np.uint8)\n",
    "for row, guess in enumerate(starting_possibilities):\n",
    "    for col, solution in enumerate(starting_possibilities):\n",
    "        if row > col:\n",
    "            scores[row, col] = scores[col, row]\n",
    "        else:\n",
    "            scores[row, col] = encode_score(get_score(guess, solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82053aa7-58d3-4c1a-93c8-b846638a6403",
   "metadata": {},
   "source": [
    "Hmm...that's pretty slow. I mean, I know I only need to compute the decision tree once, but I've always wanted to learn how to properly vectorize functions with NumPy. (Remember when I thought this was going to be about neural networks?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5696e76-5705-40c6-8077-e7a591866fba",
   "metadata": {},
   "source": [
    "## 2025-06-06: Efficiency, part 2\n",
    "\n",
    "This is all Gemini. I haven't studied it long enough yet to fully understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7965ac5e-f4b8-4a6b-8c28-f4d743809b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dca66b0a-2697-492f-9fa5-fc4b1a1e0561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_mastermind_score(guesses, secrets):\n",
    "    num_guesses = guesses.shape[0]\n",
    "    num_secrets = secrets.shape[0]\n",
    "    num_pegs = guesses.shape[1]\n",
    "    num_colors = 6\n",
    "\n",
    "    guesses_expanded = guesses[:, np.newaxis, :]\n",
    "    secrets_expanded = secrets[np.newaxis, :, :]\n",
    "\n",
    "    exact_matches = (guesses_expanded == secrets_expanded)\n",
    "    black_pegs_matrix = np.sum(exact_matches, axis=2, dtype=np.uint8)\n",
    "\n",
    "    temp_guesses_for_white = np.broadcast_to(guesses_expanded, (num_guesses, num_secrets, num_pegs)).copy()\n",
    "    temp_secrets_for_white = np.broadcast_to(secrets_expanded, (num_guesses, num_secrets, num_pegs)).copy()\n",
    "\n",
    "    temp_guesses_for_white[exact_matches] = 0\n",
    "    temp_secrets_for_white[exact_matches] = 0\n",
    "\n",
    "    temp_guesses_flat = temp_guesses_for_white.reshape(-1, num_pegs)\n",
    "    temp_secrets_flat = temp_secrets_for_white.reshape(-1, num_pegs)\n",
    "\n",
    "    @njit\n",
    "    def _count_matches_numba_single_pair(g_row, s_row, num_colors):\n",
    "        g_counts = np.bincount(g_row[g_row > 0], minlength=num_colors + 1)[1:]\n",
    "        s_counts = np.bincount(s_row[s_row > 0], minlength=num_colors + 1)[1:]\n",
    "        return np.sum(np.minimum(g_counts, s_counts))\n",
    "\n",
    "    @njit(parallel=True)\n",
    "    def _calculate_white_pegs_numba_all_pairs(guesses_flat, secrets_flat, num_colors):\n",
    "        num_pairs = guesses_flat.shape[0]\n",
    "        white_pegs_flat_results = np.empty(num_pairs, dtype=np.uint8)\n",
    "        for i in prange(num_pairs):\n",
    "            white_pegs_flat_results[i] = _count_matches_numba_single_pair(\n",
    "                guesses_flat[i], secrets_flat[i], num_colors\n",
    "            )\n",
    "        return white_pegs_flat_results\n",
    "\n",
    "    white_pegs_flat_results = _calculate_white_pegs_numba_all_pairs(\n",
    "        temp_guesses_flat, temp_secrets_flat, num_colors\n",
    "    )\n",
    "\n",
    "    white_pegs_matrix = white_pegs_flat_results.reshape(num_guesses, num_secrets)\n",
    "\n",
    "    return black_pegs_matrix, white_pegs_matrix\n",
    "\n",
    "def encode_mastermind_score_matrix(black_matrix, white_matrix):\n",
    "    return black_matrix * 16 + white_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e96c187-0c11-4917-b8ea-f6d916757350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.8 s, sys: 302 ms, total: 7.1 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "starting = np.array(list(product(np.arange(1, 7), repeat=4)))\n",
    "guesses = starting\n",
    "secrets = starting\n",
    "black_scores_matrix, white_scores_matrix = vectorized_mastermind_score(guesses, secrets)\n",
    "final_scores_matrix = encode_mastermind_score_matrix(black_scores_matrix, white_scores_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "612a53ba-bd7f-44df-930c-1d7debb7bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array_equal(final_scores_matrix, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071da50-0072-4230-8b2f-f127229897b0",
   "metadata": {},
   "source": [
    "Okay, that is indeed faster. Next step will be rewriting the algorithm.\n",
    "\n",
    "The options for the second guess can be limited similarly to for the first guess. I know the highest number appearing in the first guess will be 2, so for the second guess, we shouldn't use 4 unless we've also used 3, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "021eec7f-e8ea-4acd-b7a6-e4b5591fb165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wlog(guess):\n",
    "    L = sorted(set(guess), reverse=True)\n",
    "    if len(L) == 1:\n",
    "        b = L[0]\n",
    "    for i in range(len(L) - 1):\n",
    "        a, b = L[i:i+2]\n",
    "        if a > 3 and a - b > 1:\n",
    "            return False\n",
    "    if b > 3:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3814e-34c8-448d-87fd-5eb3ad0a5763",
   "metadata": {},
   "source": [
    "This should speed things up because it reduces the number of guesses to check to less than one-quarter of the total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "675c9939-7e12-4f1b-97e6-95f5daeef297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 1296)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(check_wlog(guess) for guess in starting_possibilities), len(starting_possibilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
